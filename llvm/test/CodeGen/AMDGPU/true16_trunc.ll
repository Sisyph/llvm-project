; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -march=amdgcn -mcpu=gfx1100 -verify-machineinstrs < %s | FileCheck -check-prefix=CHECK %s

  ; Function Attrs: nounwind
  define amdgpu_cs void @_amdgpu_cs_main(<4 x i32> inreg %buf_in, <4 x i32> inreg %buf_out, i32 inreg %idx0, i32 inreg %idx1, i32 inreg %idx2) {
; Mostly care about no crash
; CHECK-LABEL: _amdgpu_cs_main:
; CHECK:       ; %bb.0: ; %.entry
; CHECK-NEXT:    v_dual_mov_b32 v0, s8 :: v_dual_mov_b32 v1, s9
; CHECK-NEXT:    s_clause 0x1
; CHECK-NEXT:    buffer_load_u16 v0, v0, s[0:3], 0 offen
; CHECK-NEXT:    buffer_load_u16 v1, v1, s[0:3], 0 offen
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    v_add_f16_e32 v0.l, v0.l, v1.l
; CHECK-NEXT:    v_mov_b32_e32 v1, s10
; CHECK-NEXT:    buffer_store_b16 v0, v1, s[4:7], 0 offen
; CHECK-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; CHECK-NEXT:    s_endpgm
  .entry:
    %0 = call i16 @llvm.amdgcn.raw.buffer.load.i16(<4 x i32> %buf_in, i32 %idx0, i32 0, i32 0)
    %1 = bitcast i16 %0 to half
    %2 = call i16 @llvm.amdgcn.raw.buffer.load.i16(<4 x i32> %buf_in, i32 %idx1, i32 0, i32 0)
    %3 = bitcast i16 %2 to half
    %4 = fadd reassoc nnan nsz arcp contract afn half %1, %3
    %5 = bitcast half %4 to <1 x i16>
    %6 = extractelement <1 x i16> %5, i64 0
    call void @llvm.amdgcn.raw.buffer.store.i16(i16 %6, <4 x i32> %buf_out, i32 %idx2, i32 0, i32 0)
    ret void
  }

  ; Function Attrs: nounwind
  define amdgpu_cs void @_amdgpu_cs_main_not_true16(<4 x i32> inreg %buf_in, <4 x i32> inreg %buf_out, i32 inreg %idx0, i32 inreg %idx1, i32 inreg %idx2) {
; Mostly care about no crash
; TODO-GFX11_16BIT this test is redundant after true16 is implemented for sub.
; CHECK-LABEL: _amdgpu_cs_main_not_true16:
; CHECK:       ; %bb.0: ; %.entry
; CHECK-NEXT:    v_dual_mov_b32 v0, s8 :: v_dual_mov_b32 v1, s9
; CHECK-NEXT:    s_clause 0x1
; CHECK-NEXT:    buffer_load_u16 v0, v0, s[0:3], 0 offen
; CHECK-NEXT:    buffer_load_u16 v1, v1, s[0:3], 0 offen
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    v_sub_f16_e32 v0, v0, v1
; CHECK-NEXT:    v_mov_b32_e32 v1, s10
; CHECK-NEXT:    buffer_store_b16 v0, v1, s[4:7], 0 offen
; CHECK-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; CHECK-NEXT:    s_endpgm
  .entry:
    %0 = call i16 @llvm.amdgcn.raw.buffer.load.i16(<4 x i32> %buf_in, i32 %idx0, i32 0, i32 0)
    %1 = bitcast i16 %0 to half
    %2 = call i16 @llvm.amdgcn.raw.buffer.load.i16(<4 x i32> %buf_in, i32 %idx1, i32 0, i32 0)
    %3 = bitcast i16 %2 to half
    %4 = fsub nnan nsz arcp contract afn half %1, %3
    %5 = bitcast half %4 to <1 x i16>
    %6 = extractelement <1 x i16> %5, i64 0
    call void @llvm.amdgcn.raw.buffer.store.i16(i16 %6, <4 x i32> %buf_out, i32 %idx2, i32 0, i32 0)
    ret void
  }

  ; Function Attrs: nounwind readonly willreturn
  declare i16 @llvm.amdgcn.raw.buffer.load.i16(<4 x i32>, i32, i32, i32 immarg) #3

  ; Function Attrs: nounwind willreturn writeonly
  declare void @llvm.amdgcn.raw.buffer.store.i16(i16, <4 x i32>, i32, i32, i32 immarg) #4
